<!DOCTYPE html>
<html lang="en-us" dir="ltr">
<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width">
<meta name="title" content="MiloDocs: " />
<meta name="description" content="Import a model # This guide walks through importing a GGUF, PyTorch or Safetensors model.
Importing (GGUF) # Step 1: Write a Modelfile # Start by creating a Modelfile. This file is the blueprint for your model, specifying weights, parameters, prompt templates and more.
FROM ./mistral-7b-v0.1.Q4_0.gguf Copy (Optional) many chat models require a prompt template in order to answer correctly. A default prompt template can be specified with the TEMPLATE instruction in the Modelfile:" />
<meta name="keywords" content="[]" />
<meta name="author" content="" />


<title> | MiloDocs</title>

  <link rel="stylesheet" href="/css/bundle.css">
<script src="/js/bundle.cca7746894b8b9b1c4052fd8b832a8e218fe49bcae077ac61493efc3f7ab4e71.js" integrity="sha256-zKd0aJS4ubHEBS/YuDKo4hj&#43;SbyuB3rGFJPvw/erTnE=" crossorigin="anonymous"></script>

</head>
<body class="bg-white">
  <header>
</header><nav id="topNav" class="sticky top-0 z-50 py-2 bg-white">
    <div class="max-w-screen-xl 2xl:max-w-screen-2xl mx-auto">
        <div id="topNavItemsContainer" class="flex space-x-2">
            <a href="/" class="flex items-center">
    <span class="w-5 h-5">
            <img src="/images/milo.png" alt="Logo Small" class="w-5"></span>
</a>

<div id="topNavLinks" class="flex items-center mx-2 space-x-4 text-black transition duration-300 justify-start w-1/3 font-brand font-light text-sm">
        <a href="/" aria-label="Home" class="hidden md:block">Home</a><a href="/get-started/" aria-label="Get Started" class="hidden md:block">Get Started</a>
    
    <div id="topNavPrimaryDropdown" class="hidden md:block relative group z-50">
        <a href="/" aria-label="Dropdown" class="">Dropdown</a>
        <div class="absolute left-0 mt-0 w-48 bg-white border border-gray-200 rounded-md overflow-hidden shadow-lg group-hover:block hidden p-1"><a href="/about" aria-label="About Us" class="flex px-4 py-1 text-sm text-black hover:bg-zinc-100 transition duration-100">About Us</a><a href="/services" aria-label="Services" class="flex px-4 py-1 text-sm text-black hover:bg-zinc-100 transition duration-100">Services</a><a href="/contact" aria-label="Contact" class="flex px-4 py-1 text-sm text-black hover:bg-zinc-100 transition duration-100">Contact</a></div>
    </div></div>
<div id="topNavSearch" class="flex items-center space-x-4 text-xs">
    <input type="search" id="searchInput" class="border rounded-lg p-2 focus:outline-none focus:ring-2 focus:ring-brand md:w-96 bg-zinc-100 text-black" placeholder="Search..." aria-label="Search" />
</div><div id="topNavEnd" class="flex w-1/3 justify-end">
                
                <div class="flex items-center space-x-4">
                    <button id="chatTocToggle" aria-label="Toggle Chat" class="hidden md:block"><span class="w-5 h-5"><img id="chatRob" src="/icons/robot.svg" alt="toggle" class="hidden" title="Chat Panel"><img id="chatToc" src="/icons/toc.svg" alt="toggle" class="hidden" title="TOC Panel"></span></button>
                    <button id="darkModeToggle" aria-label="Toggle Darkmode"><span class="w-5 h-5"><img id="moon" src="/icons/dark.svg" alt="moon" class="hidden" title="Dark Mode"><img id="sun" src="/icons/light.svg" alt="sun" class="hidden" title="Light Mode"></span></button>
                </div>
            </div>
        </div>
    </div>
</nav><main class="max-w-screen-xl 2xl:max-w-screen-2xl mx-auto flex"><aside id="sidebar-left" class="hidden md:flex md:translate-x-0 w-60 text-black">
    <div id="linkTree" class="sticky top-10 pt-4 h-[calc(100vh-4rem)] overflow-y-auto w-full">
        
        
        
    </div>
</aside>




<div id="pageContainer" class="w-full lg:w-3/5"><section id="articleSummarizationContainer" class="hidden border border-dotted m-4 p-4 rounded-md transition-opacity duration-500">
    <h2 class="text-3xl font-bold text-black mb-4">Article Summarization</h2>
    <div id="articleSummaryOutput" class="flex items-center justify-center p-4 my-4 bg-zinc-100 rounded-md text-black text-sm transition-all duration-300 ease-in-out">
        <div class="animate-spin h-5 w-5 mr-3 border-4 border-brand rounded-full border-t-transparent"></div>
        <p id="generationMessage">Generating summary...</p>
    </div>
</section>

  <div class="my-4">
    <nav aria-label="Breadcrumb Navigation" class="breadcrumb flex flex-wrap text-xs px-2 items-center md:px-4">
  <ol class="flex space-x-2 md:space-x-4 lg:space-x-6">
    
    <li>
      <a href="//localhost:1313/import/" class="text-black px-2 py-1 md:px-4 md:py-2 lg:px-6 rounded shadow-md block tile transition duration-300" aria-label="Breadcrumb Item" aria-current="page">
          
      </a>
    </li>
  </ol>
</nav>

  </div>
  <h1 class="text-black p-4"></h1>
  <div id="articleContent" class="p-4">
    



<h1 id="import-a-model" class="group block ">
    Import a model
    <a id="-import-a-model" href="#-import-a-model" class="hidden group-hover:inline text-current ml-2">#</a>
</h1><p>This guide walks through importing a GGUF, PyTorch or Safetensors model.</p>




<h2 id="importing-gguf" class="group block py-4">
    Importing (GGUF)
    <a id="-importing-gguf" href="#-importing-gguf" class="hidden group-hover:inline text-current ml-2">#</a>
</h2>



<h3 id="step-1-write-a-modelfile" class="group block py-4">
    Step 1: Write a <code>Modelfile</code>
    <a id="-step-1-write-a-modelfile" href="#-step-1-write-a-modelfile" class="hidden group-hover:inline text-current ml-2">#</a>
</h3><p>Start by creating a <code>Modelfile</code>. This file is the blueprint for your model, specifying weights, parameters, prompt templates and more.</p>
<div class="codeblock relative bg-zinc-800 rounded text-sm p-4">
    <pre tabindex="0"><code>FROM ./mistral-7b-v0.1.Q4_0.gguf</code></pre>
    <button class="copy-btn absolute top-2 right-2 bg-zinc-600 hover:bg-zinc-900 transition duration-300 text-white rounded px-2 py-1 text-xs focus:outline-none" onclick="copyCodeToClipboard(this)">Copy</button>
</div>

<p>(Optional) many chat models require a prompt template in order to answer correctly. A default prompt template can be specified with the <code>TEMPLATE</code> instruction in the <code>Modelfile</code>:</p>
<div class="codeblock relative bg-zinc-800 rounded text-sm p-4">
    <pre tabindex="0"><code>FROM ./mistral-7b-v0.1.Q4_0.gguf
TEMPLATE &#34;[INST] {{ .Prompt }} [/INST]&#34;</code></pre>
    <button class="copy-btn absolute top-2 right-2 bg-zinc-600 hover:bg-zinc-900 transition duration-300 text-white rounded px-2 py-1 text-xs focus:outline-none" onclick="copyCodeToClipboard(this)">Copy</button>
</div>





<h3 id="step-2-create-the-ollama-model" class="group block py-4">
    Step 2: Create the Ollama model
    <a id="-step-2-create-the-ollama-model" href="#-step-2-create-the-ollama-model" class="hidden group-hover:inline text-current ml-2">#</a>
</h3><p>Finally, create a model from your <code>Modelfile</code>:</p>
<div class="codeblock relative bg-zinc-800 rounded text-sm p-4">
    <pre tabindex="0"><code>ollama create example -f Modelfile</code></pre>
    <button class="copy-btn absolute top-2 right-2 bg-zinc-600 hover:bg-zinc-900 transition duration-300 text-white rounded px-2 py-1 text-xs focus:outline-none" onclick="copyCodeToClipboard(this)">Copy</button>
</div>





<h3 id="step-3-run-your-model" class="group block py-4">
    Step 3: Run your model
    <a id="-step-3-run-your-model" href="#-step-3-run-your-model" class="hidden group-hover:inline text-current ml-2">#</a>
</h3><p>Next, test the model with <code>ollama run</code>:</p>
<div class="codeblock relative bg-zinc-800 rounded text-sm p-4">
    <pre tabindex="0"><code>ollama run example &#34;What is your favourite condiment?&#34;</code></pre>
    <button class="copy-btn absolute top-2 right-2 bg-zinc-600 hover:bg-zinc-900 transition duration-300 text-white rounded px-2 py-1 text-xs focus:outline-none" onclick="copyCodeToClipboard(this)">Copy</button>
</div>





<h2 id="importing-pytorch--safetensors" class="group block py-4">
    Importing (PyTorch &amp; Safetensors)
    <a id="-importing-pytorch--safetensors" href="#-importing-pytorch--safetensors" class="hidden group-hover:inline text-current ml-2">#</a>
</h2><blockquote>
<p>Importing from PyTorch and Safetensors is a longer process than importing from GGUF. Improvements that make it easier are a work in progress.</p>
</blockquote>




<h3 id="setup" class="group block py-4">
    Setup
    <a id="-setup" href="#-setup" class="hidden group-hover:inline text-current ml-2">#</a>
</h3><p>First, clone the <code>ollama/ollama</code> repo:</p>
<div class="codeblock relative bg-zinc-800 rounded text-sm p-4">
    <pre tabindex="0"><code>git clone git@github.com:ollama/ollama.git ollama
cd ollama</code></pre>
    <button class="copy-btn absolute top-2 right-2 bg-zinc-600 hover:bg-zinc-900 transition duration-300 text-white rounded px-2 py-1 text-xs focus:outline-none" onclick="copyCodeToClipboard(this)">Copy</button>
</div>

<p>and then fetch its <code>llama.cpp</code> submodule:</p>
<div class="codeblock relative bg-zinc-800 rounded text-sm p-4">
    <div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>git submodule init
</span></span><span style="display:flex;"><span>git submodule update llm/llama.cpp</span></span></code></pre></div>
    <button class="copy-btn absolute top-2 right-2 bg-zinc-600 hover:bg-zinc-900 transition duration-300 text-white rounded px-2 py-1 text-xs focus:outline-none" onclick="copyCodeToClipboard(this)">Copy</button>
</div>

<p>Next, install the Python dependencies:</p>
<div class="codeblock relative bg-zinc-800 rounded text-sm p-4">
    <pre tabindex="0"><code>python3 -m venv llm/llama.cpp/.venv
source llm/llama.cpp/.venv/bin/activate
pip install -r llm/llama.cpp/requirements.txt</code></pre>
    <button class="copy-btn absolute top-2 right-2 bg-zinc-600 hover:bg-zinc-900 transition duration-300 text-white rounded px-2 py-1 text-xs focus:outline-none" onclick="copyCodeToClipboard(this)">Copy</button>
</div>

<p>Then build the <code>quantize</code> tool:</p>
<div class="codeblock relative bg-zinc-800 rounded text-sm p-4">
    <pre tabindex="0"><code>make -C llm/llama.cpp quantize</code></pre>
    <button class="copy-btn absolute top-2 right-2 bg-zinc-600 hover:bg-zinc-900 transition duration-300 text-white rounded px-2 py-1 text-xs focus:outline-none" onclick="copyCodeToClipboard(this)">Copy</button>
</div>





<h3 id="clone-the-huggingface-repository-optional" class="group block py-4">
    Clone the HuggingFace repository (optional)
    <a id="-clone-the-huggingface-repository-optional" href="#-clone-the-huggingface-repository-optional" class="hidden group-hover:inline text-current ml-2">#</a>
</h3><p>If the model is currently hosted in a HuggingFace repository, first clone that repository to download the raw model.</p>
<p>Install <a href="https://docs.github.com/en/repositories/working-with-files/managing-large-files/installing-git-large-file-storage">Git LFS</a>, verify it&rsquo;s installed, and then clone the model&rsquo;s repository:</p>
<div class="codeblock relative bg-zinc-800 rounded text-sm p-4">
    <pre tabindex="0"><code>git lfs install
git clone https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1 model</code></pre>
    <button class="copy-btn absolute top-2 right-2 bg-zinc-600 hover:bg-zinc-900 transition duration-300 text-white rounded px-2 py-1 text-xs focus:outline-none" onclick="copyCodeToClipboard(this)">Copy</button>
</div>





<h3 id="convert-the-model" class="group block py-4">
    Convert the model
    <a id="-convert-the-model" href="#-convert-the-model" class="hidden group-hover:inline text-current ml-2">#</a>
</h3><blockquote>
<p>Note: some model architectures require using specific convert scripts. For example, Qwen models require running <code>convert-hf-to-gguf.py</code> instead of <code>convert.py</code></p>
</blockquote>
<div class="codeblock relative bg-zinc-800 rounded text-sm p-4">
    <pre tabindex="0"><code>python llm/llama.cpp/convert.py ./model --outtype f16 --outfile converted.bin</code></pre>
    <button class="copy-btn absolute top-2 right-2 bg-zinc-600 hover:bg-zinc-900 transition duration-300 text-white rounded px-2 py-1 text-xs focus:outline-none" onclick="copyCodeToClipboard(this)">Copy</button>
</div>





<h3 id="quantize-the-model" class="group block py-4">
    Quantize the model
    <a id="-quantize-the-model" href="#-quantize-the-model" class="hidden group-hover:inline text-current ml-2">#</a>
</h3><div class="codeblock relative bg-zinc-800 rounded text-sm p-4">
    <pre tabindex="0"><code>llm/llama.cpp/quantize converted.bin quantized.bin q4_0</code></pre>
    <button class="copy-btn absolute top-2 right-2 bg-zinc-600 hover:bg-zinc-900 transition duration-300 text-white rounded px-2 py-1 text-xs focus:outline-none" onclick="copyCodeToClipboard(this)">Copy</button>
</div>





<h3 id="step-3-write-a-modelfile" class="group block py-4">
    Step 3: Write a <code>Modelfile</code>
    <a id="-step-3-write-a-modelfile" href="#-step-3-write-a-modelfile" class="hidden group-hover:inline text-current ml-2">#</a>
</h3><p>Next, create a <code>Modelfile</code> for your model:</p>
<div class="codeblock relative bg-zinc-800 rounded text-sm p-4">
    <pre tabindex="0"><code>FROM quantized.bin
TEMPLATE &#34;[INST] {{ .Prompt }} [/INST]&#34;</code></pre>
    <button class="copy-btn absolute top-2 right-2 bg-zinc-600 hover:bg-zinc-900 transition duration-300 text-white rounded px-2 py-1 text-xs focus:outline-none" onclick="copyCodeToClipboard(this)">Copy</button>
</div>





<h3 id="step-4-create-the-ollama-model" class="group block py-4">
    Step 4: Create the Ollama model
    <a id="-step-4-create-the-ollama-model" href="#-step-4-create-the-ollama-model" class="hidden group-hover:inline text-current ml-2">#</a>
</h3><p>Finally, create a model from your <code>Modelfile</code>:</p>
<div class="codeblock relative bg-zinc-800 rounded text-sm p-4">
    <pre tabindex="0"><code>ollama create example -f Modelfile</code></pre>
    <button class="copy-btn absolute top-2 right-2 bg-zinc-600 hover:bg-zinc-900 transition duration-300 text-white rounded px-2 py-1 text-xs focus:outline-none" onclick="copyCodeToClipboard(this)">Copy</button>
</div>





<h3 id="step-5-run-your-model" class="group block py-4">
    Step 5: Run your model
    <a id="-step-5-run-your-model" href="#-step-5-run-your-model" class="hidden group-hover:inline text-current ml-2">#</a>
</h3><p>Next, test the model with <code>ollama run</code>:</p>
<div class="codeblock relative bg-zinc-800 rounded text-sm p-4">
    <pre tabindex="0"><code>ollama run example &#34;What is your favourite condiment?&#34;</code></pre>
    <button class="copy-btn absolute top-2 right-2 bg-zinc-600 hover:bg-zinc-900 transition duration-300 text-white rounded px-2 py-1 text-xs focus:outline-none" onclick="copyCodeToClipboard(this)">Copy</button>
</div>





<h2 id="publishing-your-model-optional--early-alpha" class="group block py-4">
    Publishing your model (optional – early alpha)
    <a id="-publishing-your-model-optional--early-alpha" href="#-publishing-your-model-optional--early-alpha" class="hidden group-hover:inline text-current ml-2">#</a>
</h2><p>Publishing models is in early alpha. If you&rsquo;d like to publish your model to share with others, follow these steps:</p>
<ol>
<li>Create <a href="https://ollama.com/signup">an account</a></li>
<li>Copy your Ollama public key:</li>
</ol>
<ul>
<li>macOS: <code>cat ~/.ollama/id_ed25519.pub</code></li>
<li>Windows: <code>type %USERPROFILE%\.ollama\id_ed25519.pub</code></li>
<li>Linux: <code>cat /usr/share/ollama/.ollama/id_ed25519.pub</code></li>
</ul>
<ol start="3">
<li>Add your public key to your <a href="https://ollama.com/settings/keys">Ollama account</a></li>
</ol>
<p>Next, copy your model to your username&rsquo;s namespace:</p>
<div class="codeblock relative bg-zinc-800 rounded text-sm p-4">
    <pre tabindex="0"><code>ollama cp example &lt;your username&gt;/example</code></pre>
    <button class="copy-btn absolute top-2 right-2 bg-zinc-600 hover:bg-zinc-900 transition duration-300 text-white rounded px-2 py-1 text-xs focus:outline-none" onclick="copyCodeToClipboard(this)">Copy</button>
</div>

<p>Then push the model:</p>
<div class="codeblock relative bg-zinc-800 rounded text-sm p-4">
    <pre tabindex="0"><code>ollama push &lt;your username&gt;/example</code></pre>
    <button class="copy-btn absolute top-2 right-2 bg-zinc-600 hover:bg-zinc-900 transition duration-300 text-white rounded px-2 py-1 text-xs focus:outline-none" onclick="copyCodeToClipboard(this)">Copy</button>
</div>

<p>After publishing, your model will be available at <code>https://ollama.com/&lt;your username&gt;/example</code>.</p>




<h2 id="quantization-reference" class="group block py-4">
    Quantization reference
    <a id="-quantization-reference" href="#-quantization-reference" class="hidden group-hover:inline text-current ml-2">#</a>
</h2><p>The quantization options are as follow (from highest highest to lowest levels of quantization). Note: some architectures such as Falcon do not support K quants.</p>
<ul>
<li><code>q2_K</code></li>
<li><code>q3_K</code></li>
<li><code>q3_K_S</code></li>
<li><code>q3_K_M</code></li>
<li><code>q3_K_L</code></li>
<li><code>q4_0</code> (recommended)</li>
<li><code>q4_1</code></li>
<li><code>q4_K</code></li>
<li><code>q4_K_S</code></li>
<li><code>q4_K_M</code></li>
<li><code>q5_0</code></li>
<li><code>q5_1</code></li>
<li><code>q5_K</code></li>
<li><code>q5_K_S</code></li>
<li><code>q5_K_M</code></li>
<li><code>q6_K</code></li>
<li><code>q8_0</code></li>
<li><code>f16</code></li>
</ul>

  </div>
  <div class="p-4">
    
<div class="mt-8 flex justify-between items-center">
    
        <a href="/gpu/" class="tile text-black py-2 px-4 rounded-r-md transition duration-300">  </a>
    

    
        <a href="/linux/" class="tile text-black py-2 px-4 rounded-l-md transition duration-300">  </a>
    
</div>
  </div>

    </div><div id="searchResultsContainer" class="hidden w-full lg:w-3/5 p-4" data-productFilter="">
    
</div><aside id="sidebar-right" class="hidden lg:block w-60">
  
    <div id="tocContainer" class="hidden toc sticky top-10 pt-4 h-[calc(100vh-4rem)] overflow-y-auto text-sm text-black transition duration-300"> 
    <nav id="TableOfContents">
  <ul>
    <li><a href="#importing-gguf">Importing (GGUF)</a>
      <ul>
        <li><a href="#step-1-write-a-modelfile">Step 1: Write a <code>Modelfile</code></a></li>
        <li><a href="#step-2-create-the-ollama-model">Step 2: Create the Ollama model</a></li>
        <li><a href="#step-3-run-your-model">Step 3: Run your model</a></li>
      </ul>
    </li>
    <li><a href="#importing-pytorch--safetensors">Importing (PyTorch &amp; Safetensors)</a>
      <ul>
        <li><a href="#setup">Setup</a></li>
        <li><a href="#clone-the-huggingface-repository-optional">Clone the HuggingFace repository (optional)</a></li>
        <li><a href="#convert-the-model">Convert the model</a></li>
        <li><a href="#quantize-the-model">Quantize the model</a></li>
        <li><a href="#step-3-write-a-modelfile">Step 3: Write a <code>Modelfile</code></a></li>
        <li><a href="#step-4-create-the-ollama-model">Step 4: Create the Ollama model</a></li>
        <li><a href="#step-5-run-your-model">Step 5: Run your model</a></li>
      </ul>
    </li>
    <li><a href="#publishing-your-model-optional--early-alpha">Publishing your model (optional – early alpha)</a></li>
    <li><a href="#quantization-reference">Quantization reference</a></li>
  </ul>
</nav>
</div>
  
  
    <div id="chatContainer" class="hidden sticky top-16 h-[calc(100vh-5rem)] flex flex-col flex justify-end">
    <div id="chat-messages" class="flex flex-col overflow-y-auto text-base">
    </div>
    <div id="chat-controls" class="flex flex-row text-xs mt-2">
        <form id="chat-form" class="flex flex-row">
            <input id="question" type="text" aria-label="Question Input" placeholder="Ask the docs" class="h-10 border rounded-lg p-1 mr-1 focus:outline-none focus:ring-2 focus:ring-brand" />
            <button id="sendButton" aria-label="Send" class="flex items-center bg-brand my-1  hover:bg-black text-white p-1 mr-1 rounded-lg shadow-lg transition duration-300"><img src="/icons/send.svg" alt="Send" class="w-5 h-5"></button>
        </form>
        <button id="clearAll" aria-label="Delete All"  class="flex items-center bg-black my-1 hover:bg-red-600 text-white p-1 rounded-lg shadow-lg transition duration-300"><img src="/icons/delete.svg" alt="Delete" class="w-5 h-5"></button>
    </div>
</div>
  
</aside>
</main>
  <footer>


<script src="https://cdn.jsdelivr.net/npm/algoliasearch@latest/dist/algoliasearch-lite.umd.js" defer></script>
</footer>
</body>
</html>
