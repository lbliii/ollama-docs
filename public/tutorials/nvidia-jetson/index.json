{
    "id": "a3edd3036b5d08d0a043d0f7659a0cdf",
    "title": "Nvidia jetson",
    "description":"no description",
    "lastCommit": "0001-01-01 00:00:00 +0000 UTC",
    "version": "<no value>.<no value>.<no value>",
    "section":"tutorials",
    "parent": "MiloDocs",
    "isPage":true,
    "isSection":false,
    "pageKind":"page",
    "bundleType":"",
    "uri": "//localhost:1313/tutorials/nvidia-jetson/",
    "relURI": "/tutorials/nvidia-jetson/",
    "body": " Running Ollama on NVIDIA Jetson Devices # Ollama runs well on NVIDIA Jetson Devices and should run out of the box with the standard installation instructions.\nThe following has been tested on JetPack 5.1.2, but should also work on JetPack 6.0.\nInstall Ollama via standard Linux command (ignore the 404 error): curl https://ollama.com/install.sh | sh Pull the model you want to use (e.g. mistral): ollama pull mistral Start an interactive session: ollama run mistral And that\u0026rsquo;s it!\nRunning Ollama in Docker # When running GPU accelerated applications in Docker, it is highly recommended to use dusty-nv jetson-containers repo.\n",
    "tags": []
}