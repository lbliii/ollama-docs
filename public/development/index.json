{
    "id": "c51f1b783d6e6b3bc97ce5906e9605d3",
    "title": "Development",
    "description":"no description",
    "lastCommit": "0001-01-01 00:00:00 +0000 UTC",
    "version": "<no value>.<no value>.<no value>",
    "section":"no section",
    "parent": "MiloDocs",
    "isPage":true,
    "isSection":false,
    "pageKind":"page",
    "bundleType":"",
    "uri": "//localhost:1313/development/",
    "relURI": "/development/",
    "body": " Development # Install required tools:\ncmake version 3.24 or higher go version 1.22 or higher gcc version 11.4.0 or higher brew install go cmake gcc Copy Optionally enable debugging and more verbose logging:\n# At build time export CGO_CFLAGS=\u0026#34;-g\u0026#34; # At runtime export OLLAMA_DEBUG=1 Copy Get the required libraries and build the native LLM code:\ngo generate ./... Copy Then build ollama:\ngo build . Copy Now you can run ollama:\n./ollama Copy Linux # Linux CUDA (NVIDIA) # Your operating system distribution may already have packages for NVIDIA CUDA. Distro packages are often preferable, but instructions are distro-specific. Please consult distro-specific docs for dependencies if available!\nInstall cmake and golang as well as NVIDIA CUDA development and runtime packages.\nTypically the build scripts will auto-detect CUDA, however, if your Linux distro or installation approach uses unusual paths, you can specify the location by specifying an environment variable CUDA_LIB_DIR to the location of the shared libraries, and CUDACXX to the location of the nvcc compiler. You can customize a set of target CUDA architectures by setting CMAKE_CUDA_ARCHITECTURES (e.g. \u0026ldquo;50;60;70\u0026rdquo;)\nThen generate dependencies:\ngo generate ./... Copy Then build the binary:\ngo build . Copy Linux ROCm (AMD) # Your operating system distribution may already have packages for AMD ROCm and CLBlast. Distro packages are often preferable, but instructions are distro-specific. Please consult distro-specific docs for dependencies if available!\nInstall CLBlast and ROCm development packages first, as well as cmake and golang.\nTypically the build scripts will auto-detect ROCm, however, if your Linux distro or installation approach uses unusual paths, you can specify the location by specifying an environment variable ROCM_PATH to the location of the ROCm install (typically /opt/rocm), and CLBlast_DIR to the location of the CLBlast install (typically /usr/lib/cmake/CLBlast). You can also customize the AMD GPU targets by setting AMDGPU_TARGETS (e.g. AMDGPU_TARGETS=\u0026quot;gfx1101;gfx1102\u0026quot;)\ngo generate ./... Copy Then build the binary:\ngo build . Copy ROCm requires elevated privileges to access the GPU at runtime. On most distros you can add your user account to the render group, or run as root.\nAdvanced CPU Settings # By default, running go generate ./... will compile a few different variations of the LLM library based on common CPU families and vector math capabilities, including a lowest-common-denominator which should run on almost any 64 bit CPU somewhat slowly. At runtime, Ollama will auto-detect the optimal variation to load. If you would like to build a CPU-based build customized for your processor, you can set OLLAMA_CUSTOM_CPU_DEFS to the llama.cpp flags you would like to use. For example, to compile an optimized binary for an Intel i9-9880H, you might use:\nOLLAMA_CUSTOM_CPU_DEFS=\u0026#34;-DLLAMA_AVX=on -DLLAMA_AVX2=on -DLLAMA_F16C=on -DLLAMA_FMA=on\u0026#34; go generate ./... go build . Copy Containerized Linux Build # If you have Docker available, you can build linux binaries with ./scripts/build_linux.sh which has the CUDA and ROCm dependencies included. The resulting binary is placed in ./dist\nWindows # Note: The windows build for Ollama is still under development.\nInstall required tools:\nMSVC toolchain - C/C++ and cmake as minimal requirements Go version 1.22 or higher MinGW (pick one variant) with GCC. MinGW-w64 MSYS2 $env:CGO_ENABLED=\u0026#34;1\u0026#34; go generate ./... go build . Copy Windows CUDA (NVIDIA) # In addition to the common Windows development tools described above, install CUDA after installing MSVC.\nNVIDIA CUDA Windows ROCm (AMD Radeon) # In addition to the common Windows development tools described above, install AMDs HIP package after installing MSVC.\nAMD HIP Strawberry Perl Lastly, add ninja.exe included with MSVC to the system path (e.g. C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\Ninja).\n",
    "tags": []
}