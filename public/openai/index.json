{
    "id": "3c125f0f2de25aea767048f0c27405fc",
    "title": "Openai",
    "description":"no description",
    "lastCommit": "0001-01-01 00:00:00 +0000 UTC",
    "version": "<no value>.<no value>.<no value>",
    "section":"no section",
    "parent": "MiloDocs",
    "isPage":true,
    "isSection":false,
    "pageKind":"page",
    "bundleType":"",
    "uri": "//localhost:1313/openai/",
    "relURI": "/openai/",
    "body": " OpenAI compatibility # Note: OpenAI compatibility is experimental and is subject to major adjustments including breaking changes. For fully-featured access to the Ollama API, see the Ollama Python library, JavaScript library and REST API.\nOllama provides experimental compatibility with parts of the OpenAI API to help connect existing applications to Ollama.\nUsage # OpenAI Python library # from openai import OpenAI client = OpenAI( base_url=\u0026#39;http://localhost:11434/v1/\u0026#39;, # required but ignored api_key=\u0026#39;ollama\u0026#39;, ) chat_completion = client.chat.completions.create( messages=[ { \u0026#39;role\u0026#39;: \u0026#39;user\u0026#39;, \u0026#39;content\u0026#39;: \u0026#39;Say this is a test\u0026#39;, } ], model=\u0026#39;llama3\u0026#39;, ) Copy OpenAI JavaScript library # import OpenAI from \u0026#39;openai\u0026#39; const openai = new OpenAI({ baseURL: \u0026#39;http://localhost:11434/v1/\u0026#39;, // required but ignored apiKey: \u0026#39;ollama\u0026#39;, }) const chatCompletion = await openai.chat.completions.create({ messages: [{ role: \u0026#39;user\u0026#39;, content: \u0026#39;Say this is a test\u0026#39; }], model: \u0026#39;llama3\u0026#39;, }) Copy curl # curl http://localhost:11434/v1/chat/completions \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{ \u0026#34;model\u0026#34;: \u0026#34;llama3\u0026#34;, \u0026#34;messages\u0026#34;: [ { \u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;You are a helpful assistant.\u0026#34; }, { \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;Hello!\u0026#34; } ] }\u0026#39; Copy Endpoints # /v1/chat/completions # Supported features # Chat completions Streaming JSON mode Reproducible outputs Vision Function calling Logprobs Supported request fields # model messages Text content Array of content parts frequency_penalty presence_penalty response_format seed stop stream temperature top_p max_tokens logit_bias tools tool_choice user n Notes # Setting seed will always set temperature to 0 finish_reason will always be stop usage.prompt_tokens will be 0 for completions where prompt evaluation is cached Models # Before using a model, pull it locally ollama pull:\nollama pull llama3 Copy Default model names # For tooling that relies on default OpenAI model names such as gpt-3.5-turbo, use ollama cp to copy an existing model name to a temporary name:\nollama cp llama3 gpt-3.5-turbo Copy Afterwards, this new model name can be specified the model field:\ncurl http://localhost:11434/v1/chat/completions \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{ \u0026#34;model\u0026#34;: \u0026#34;gpt-3.5-turbo\u0026#34;, \u0026#34;messages\u0026#34;: [ { \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;Hello!\u0026#34; } ] }\u0026#39; Copy ",
    "tags": []
}